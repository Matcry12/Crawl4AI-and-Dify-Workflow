# ============================================================================
# Crawl4AI Configuration - Topic-Based Architecture
# ============================================================================
# Copy this file to .env and update with your actual values
# cp .env.example .env
# ============================================================================

# ============================================================================
# DATABASE CONFIGURATION (Topic-Based Architecture)
# ============================================================================

# PostgreSQL connection string (full URL)
# Format: postgresql://[user]:[password]@[host]:[port]/[database]
DATABASE_URL=postgresql://your_user@localhost:5432/crawl4ai

# Or configure components separately (if DATABASE_URL not set)
DB_NAME=crawl4ai
DB_USER=your_user
DB_HOST=localhost
DB_PORT=5432
DB_PASSWORD=

# ============================================================================
# TOPIC-BASED ARCHITECTURE SETTINGS
# ============================================================================

# Enable topic-based extraction and matching
ENABLE_TOPIC_BASED=true

# Embedding provider for topic matching and document storage
# Options:
#   - "gemini" (default): Uses Gemini text-embedding-004 (768D, $0.000025/1K tokens)
#   - "sentence-transformers": Local models (384D, free but requires local resources)
EMBEDDING_PROVIDER=gemini

# Embedding model (optional, uses defaults if not specified)
# For Gemini: text-embedding-004 (768 dims, default)
# For sentence-transformers: all-MiniLM-L6-v2 (384 dims)
EMBEDDING_MODEL=

# Topic similarity thresholds
TOPIC_SIMILARITY_THRESHOLD=0.75        # Minimum similarity for embedding matches (0.0-1.0)
TOPIC_HIGH_CONFIDENCE_THRESHOLD=0.90   # Skip LLM if similarity above this

# ============================================================================
# LLM CONFIGURATION
# ============================================================================

# Primary LLM for content extraction (smart model)
EXTRACTION_LLM_MODEL=gemini/gemini-2.0-flash-exp
GEMINI_API_KEY=your-gemini-api-key-here

# Optional: Other LLM providers
# OPENAI_API_KEY=your-openai-api-key-here
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Optional: Custom LLM endpoint
# CUSTOM_LLM_BASE_URL=http://localhost:8000/v1
# CUSTOM_LLM_API_KEY=your_custom_api_key

# Fast LLM for categorization and naming (cost-efficient)
NAMING_LLM_MODEL=gemini/gemini-1.5-flash

# Topic matching LLM (for ambiguous cases)
MATCHING_LLM_MODEL=gemini/gemini-1.5-flash

# ============================================================================
# RATE LIMITING (For Free Tier API Usage)
# ============================================================================

# Enable rate limiting to avoid hitting API limits
ENABLE_RATE_LIMITING=false

# Simple delay mode: Wait X seconds between each LLM call
# Good for free tier: 15 calls/min = 4 seconds delay
# Recommended values: 4.0 for free tier, 0.5 for paid tier
API_DELAY_SECONDS=4.0

# Alternative: Token bucket mode (allows bursts)
# Maximum LLM API calls per minute
# API_CALLS_PER_MINUTE=15

# Embedding API delay (embeddings are usually cheaper)
EMBEDDING_DELAY_SECONDS=0.1

# ============================================================================
# DIFY INTEGRATION (Optional - for RAG queries)
# ============================================================================

# Dify backend URL and API key
DIFY_API_KEY=your-dify-api-key-here
DIFY_BASE_URL=http://localhost:8088

# Sync to Dify after backend storage (optional)
SYNC_TO_DIFY=false

# ============================================================================
# CRAWLING SETTINGS
# ============================================================================

# Maximum pages to crawl per session
MAX_PAGES=50

# Maximum crawl depth
MAX_DEPTH=3

# Enable dual-mode content processing
ENABLE_DUAL_MODE=true

# Use intelligent content analysis for mode selection
USE_INTELLIGENT_MODE=true

# ============================================================================
# RESILIENCE & ERROR HANDLING
# ============================================================================

# Enable resilience features (checkpointing, failure queue)
ENABLE_RESILIENCE=true

# Maximum retries for failed operations
MAX_RETRIES=3

# ============================================================================
# PERFORMANCE SETTINGS
# ============================================================================

# Database connection pool size
DB_POOL_MIN_SIZE=5
DB_POOL_MAX_SIZE=20

# Concurrent crawling workers
CONCURRENT_WORKERS=3

# ============================================================================
# LOGGING
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================================================
# SETUP INSTRUCTIONS
# ============================================================================
# 1. Copy this file: cp .env.example .env
# 2. Set DATABASE_URL with your PostgreSQL connection
# 3. Set GEMINI_API_KEY with your API key
# 4. Run database setup: ./setup_database.sh
# 5. Test database: python3 test_database.py
# 6. Start crawling!
#
# For more information, see docs/TOPIC_BASED_ARCHITECTURE.md
